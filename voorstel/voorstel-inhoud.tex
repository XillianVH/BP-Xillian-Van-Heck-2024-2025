%---------- Inleiding ---------------------------------------------------------
\section{Inleiding}%
\label{sec:inleiding}

Binnen de Colruyt Group wordt er binnen de afdeling Smart Innovations gewerkt aan technologieën om het winkelproces efficiënter en klantvriendelijker te maken. Een van deze innovaties is het easy Self Check-out systeem, dat gebruik maakt van camera’s aan de kassa om automatisch te detecteren welke producten zich in de winkelkar bevinden. Dit systeem maakt gebruik van een YOLO-gebaseerd objectdetectiemodel om producten te herkennen, maar ondervindt momenteel moeilijkheden bij het onderscheiden van sterk gerelateerde producten, vooral producten met gelijkaardige verpakkingen.
Om dit probleem aan te pakken, richt dit onderzoek zich op het trainen van een aanvullend YOLO-model dat producttitels op verpakkingen kan herkennen op basis van afbeeldingen van de producten. Door de titels op de verpakking van producten te herkennen, kan het model producten beter onderscheiden en de nauwkeurigheid van het check-out systeem verbeteren. Daarom is het doel van dit project om een detectiemodel te ontwikkelen dat specifiek gefocust is op het lokaliseren van producttitels als visuele referentiepunten.
Binnen de afdeling Smart Innovations van Colruyt is een fotobooth gebouwd met meerdere camera’s en een draaitafel om afbeeldingen van producten uit verschillende hoeken vast te leggen. Deze setup zorgt voor consistente en veelzijdige beelddata, cruciaal voor een robuust deep learning model. De verzamelde data wordt gelabeld op basis van zichtbare producttitels en vervolgens gebruikt om YOLO-modellen te trainen en te vergelijken.
Ten slotte wordt onderzocht hoe de gedetecteerde titels met OCR kunnen worden gelezen, zodat het systeem niet alleen de locatie, maar ook de inhoud van de titel kan gebruiken voor classificatie.
\subsection*{Onderzoeksvraag}
De centrale onderzoeksvraag luidt:

\begin{center}
    \textit{Hoe kan een YOLO-model voor producttitelherkenning de nauwkeurigheid van productdetectie binnen het Self Check-out systeem van Colruyt verbeteren?}
\end{center}

\subsection*{Onderzoeksdoelstelling}
De onderzoeksdoelstelling is het creëren van een model dat producttitels accuraat kan detecteren en dat getest wordt op verschillende producten. Het eindresultaat omvat niet alleen een getraind model, maar ook een analyse van de prestaties, inclusief validatietesten. Dit onderzoek biedt een meerwaarde voor Colruyt, omdat het de efficiëntie en betrouwbaarheid van het Self Check-out systeem verhoogt. Hierdoor kunnen zowel klanten als medewerkers van de winkels profiteren van een snellere en betere werking van het Check-out systeem.

%---------- Stand van zaken ---------------------------------------------------

\section{Literatuurstudie}%
\label{sec:literatuurstudie}

\subsection{Objectdetectie en Neurale Netwerken}

\subsubsection{Wat is objectdetectie en hoe werkt het?}
Objectdetectie is een combinatie van objectclassificatie en lokalisatie. Deze techniek lokaliseert objecten binnen een afbeelding en voert per bounding box een classificatie uit. Bij het lokaliseren van de objecten wordt er binnen de afbeelding een rechthoek of bounding box rond een object getekend. Deze bounding boxen worden vervolgens geclassificeerd.

In de context van dit onderzoek betekent dit dat de titels die op de afbeelding te zien zijn, moeten worden gelokaliseerd en vervolgens moeten worden geclassificeerd als een product \autocite{wulteputteefficient}.

\subsubsection{Uitleg over Convolutional Neural Networks (CNNs) en hun rol in objectdetectie}
Convolutional Neural Networks (CNNs) zijn speciaal ontworpen om efficiënt om te gaan met meerdimensionale invoer, zoals afbeeldingen, door gebruik te maken van een techniek die convolutie wordt genoemd. In tegenstelling tot klassieke neurale netwerken, die werken met eendimensionale vectoren, zijn CNN's in staat om belangrijke informatie uit aanliggende pixels te halen, waardoor ze veel effectiever zijn voor taken zoals objectdetectie.

Een CNN bestaat uit verschillende lagen, waarvan de belangrijkste de convolutionele lagen zijn. In deze lagen wordt een set filters (of kernels) over de afbeelding geschoven. Elke filter leert specifieke kenmerken van de afbeelding, zoals randen of kleurovergangen. Door deze filters toe te passen op verschillende delen van de afbeelding ontstaat er een feature map \autocite{wulteputteefficient}. 

Als je bijvoorbeeld een foto van een hond hebt, zal het CNN eerst kleine basiselementen leren, zoals randen en hoeken. Later in het netwerk worden die basiskenmerken samengevoegd tot grotere objectkenmerken, zoals de oren, ogen en poten van de hond. Dit maakt de CNN krachtig voor beeldherkenning.

\subsubsection{Verschillende objectdetectiemethoden}
\begin{itemize}
    \item \textbf{RCNN (Region-based Convolutional Neural Networks)}: Verdeelt een afbeelding in meerdere regio’s en gebruikt een CNN om elk van deze regio’s te classificeren.
    \item \textbf{Fast RCNN}: Een verbeterde versie van RCNN waarbij de afbeelding eerst door een CNN wordt gehaald om feature maps te verkrijgen, waaruit regio’s worden gehaald en geclassificeerd.
    \item \textbf{Faster RCNN}: Maakt gebruik van een Region Proposal Network (RPN) om regio’s automatisch voor te stellen.
    \item \textbf{SSD (Single Shot Multibox Detector)}: Verdeelt de afbeeldingen in meerdere cellen en voorspelt gelijktijdig objecten en hun locaties in één enkele stap.
    \item \textbf{YOLO (You Only Look Once)}: Verdeelt de afbeeldingen in een raster en voorspelt objecten en hun locaties in dezelfde stap.
\end{itemize}

\subsubsection{Waarom is YOLO geschikt voor real-time productdetectie?}
YOLO is geschikt voor real-time productdetectie omdat het alles in één keer doet. Het verdeelt de afbeelding in een raster en voorspelt gelijktijdig alle objecten en hun locaties in één doorlopende stap, zonder dat het meerdere keren door de afbeelding hoeft te bewegen. Dit maakt het zeer snel en in staat om beelden in real-time te verwerken, wat essentieel is voor toepassingen waar snelheid cruciaal is.

\subsection{Productherkenning in Retail}
Objectdetectie speelt een steeds grotere rol in de automatisering van retailprocessen. Het wordt ingezet voor voorraadbeheer, real-time productherkenning en navigatie binnen winkels of magazijnen \autocite{Cai2021}. Toch zijn er grote uitdagingen verbonden aan productherkenning in supermarkten. Een belangrijke uitdaging is het onderscheid maken tussen producten met gelijkaardige verpakkingen of overlappende producten in een winkelkar. Daarnaast spelen ook belichting, reflectie en bewegingsonscherpte een rol in het verlagen van de nauwkeurigheid \autocite{Cai2021}.

In vergelijking met technieken zoals RFID of barcode-scanning biedt visuele objectdetectie een voordeel omdat het werkt zonder fysiek contact en ook inzetbaar is wanneer labels onzichtbaar of beschadigd zijn. Visuele detectie maakt bovendien gebruik van context, wat barcode- of RFID-systemen niet doen \autocite{Desmarescaux2025}.

\subsection{Producttitelherkenning met AI}
Bij het herkennen van producttitels is er een onderscheid tussen objectdetectie en optische tekenherkenning (OCR). OCR-technologieën, zoals Tesseract, zijn gericht op het herkennen van tekst in beelden, maar zijn gevoelig voor schuine hoeken, slechte belichting of reflecties. Objectdetectiemodellen zoals YOLO kunnen teksten detecteren als objecten, zelfs wanneer de tekst moeilijk leesbaar is, en vormen zo een betere basis voor OCR-verwerking \autocite{Desmarescaux2025}.

Een bijkomend probleem in tekstherkenning op verpakkingen is de inconsistentie in lettertype, grootte, kleur en oriëntatie. \textcite{Desmarescaux2025} bieden hier een oplossing door modellen toe te laten om nieuwe teksten of producten te herkennen aan de hand van slechts één voorbeeld per klasse. Dit vermindert de behoefte aan grote, gelabelde datasets en laat toe om flexibeler te reageren op veranderende verpakkingen.

\subsection{Dataverzameling en Annotatie voor AI-Modellen}
Een cruciale factor voor het succes van deep learning-modellen zoals YOLO is de kwaliteit van de gebruikte trainingsdata. Volgens \textcite{Bertossi2020} kan de kwaliteit van data rechtstreeks worden gelinkt aan de resultaten en betrouwbaarheid van AI-modellen. Wanneer een model fouten maakt, is dit vaak te herleiden tot het gebrek, inconsistentie en de kwaliteit van de data.

\begin{itemize}
    \item \textbf{Het belang van een kwalitatieve dataset voor YOLO-training.} \\
    YOLO (You Only Look Once) is een objectdetectiemodel dat sterk afhankelijk is van nauwkeurige bounding boxes. Fouten in de annotatie hebben invloed op de prestaties van het model en zorgen voor een mindere nauwkeurigheid. Dit benadrukt dat een model sterk afhankelijk is van de kwaliteit van de data, en dat fouten in de data een invloed hebben op de nauwkeurigheid van een YOLO-model \autocite{Bertossi2020}.

    \item \textbf{Hoe werkt data-annotatie (bounding boxes, labels, tools zoals LabelImg of Roboflow)?} \\
    Annotatie is het proces waarbij objecten in afbeeldingen worden aangeduid, in dit geval het aanduiden van de producttitels op afbeeldingen. De aangeduide titels noemen we masks, en deze masks worden later omgezet naar een bounding box. Bounding boxes worden gebruikt in YOLO-modellen en zijn de labels in het trainingsproces. 

    \item \textbf{Hoe de fotobooth en draaitafel helpen bij het verzamelen van consistente data.} \\
    Bij Colruyt Group is een fotobooth ontwikkeld die afbeeldingen genereert van een product uit verschillende standpunten. Dit zorgt ervoor dat er een consistente dataset wordt opgebouwd met minimale variatie en constante belichting. 
\end{itemize}


\subsection{Evaluatie en Validatie van Objectdetectiemodellen}

\begin{itemize}
    \item \textbf{Welke metriek(en) gebruik je om je YOLO-model te evalueren?} \\
    Voor het evalueren van het YOLO-model worden verschillende evaluatiemetrieken gebruikt. De belangrijkste zijn:
    \begin{itemize}
        \item \textbf{Mean Average Precision (mAP)}: Dit is een samengestelde metriek die het gemiddelde neemt van de Average Precision (AP) over alle objectklassen. AP is gebaseerd op de precisie-recall curve en kan worden berekend via de 11-punts of all-points interpolatiemethode. mAP wordt algemeen beschouwd als de standaardmetriek voor objectdetectie-evaluatie \autocite{Padilla2020}.
        \item \textbf{Intersection over Union (IoU)}: Deze metriek vergelijkt de overlap tussen de voorspelde en de werkelijke bounding box. Een detectie wordt als correct beschouwd als de IoU groter is dan een vooraf ingestelde drempelwaarde (bijv. 0{,}5).
        \item \textbf{Precision en Recall}: Precision meet het percentage juiste detecties van alle voorspellingen, terwijl recall het percentage correcte detecties meet van alle werkelijke objecten. Deze vormen samen de basis voor de precisie-recall curve, waarop AP en mAP zijn gebaseerd \autocite{Padilla2020}.
    \end{itemize}

    \item \textbf{Hoe test je je model op real-world data en zorg je voor een betrouwbare validatie?} \\
    Om het model betrouwbaar te valideren op real-world data, worden de volgende stappen gehanteerd:
    \begin{itemize}
        \item \textbf{Gebruik van een representatieve testset}: De testset moet variaties in objecttypes, omgevingen, verlichting en occlusie bevatten om een reëel gebruiksscenario na te bootsen.
        \item \textbf{Strikte scheiding van trainings-, validatie- en testdata}: Dit voorkomt overfitting en zorgt voor een eerlijke evaluatie.
        \item \textbf{Gebruik van meerdere metrieke}: Door verschillende metrieke zoals mAP@0{,}5, mAP@0{,}75 en mAP@50:5:95 te gebruiken, kan een completer beeld worden verkregen van de prestaties van het model \autocite{Padilla2020}.
        \item \textbf{Visuele inspectie van detecties}: Naast kwantitatieve evaluatie is het ook waardevol om bounding boxes visueel te controleren op foutieve of ontbrekende detecties.
    \end{itemize}
\end{itemize}


% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

Je mag deze sectie nog verder onderverdelen in subsecties als dit de structuur van de tekst kan verduidelijken.

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

Dit onderzoek volgt een experimentele aanpak waarbij een YOLO-model wordt getraind en geëvalueerd voor producttitelherkenning. De methodologie bestaat uit de volgende fasen:

\subsection{Dataverzameling}
Voor de training van het model wordt een dataset samengesteld met behulp van de fotobooth van Colruyt. De fotobooth maakt het mogelijk om producten vanuit verschillende hoeken vast te leggen, wat zorgt voor een diverse dataset. De verzamelde afbeeldingen worden gelabeld met bounding boxes rond de producttitels.

\subsection{Modeltraining}
Het YOLO-model wordt getraind met de geannoteerde dataset. Hiervoor wordt gebruik gemaakt van de volgende aanpak:
\begin{itemize}
    \item Pre-processing van afbeeldingen (resolutie-aanpassing, normalisatie);
    \item Data augmentatie om de robuustheid van het model te verhogen;
    \item Training van het YOLO-model met behulp van deep learning frameworks zoals TensorFlow of PyTorch;
    \item Hyperparameter-tuning voor optimale prestaties.
\end{itemize}

\subsection{Evaluatie en Validatie}
Het model wordt geëvalueerd met behulp van verschillende prestatie-indicatoren:
\begin{itemize}
    \item \textbf{mAP (mean Average Precision)}: meet de gemiddelde precisie van het model over verschillende objectcategorieën.
    \item \textbf{Recall en Precision}: bepalen hoe goed het model relevante objecten detecteert en incorrecte detecties minimaliseert.
    \item \textbf{IoU (Intersection over Union)}: meet de overlap tussen de voorspelde en werkelijke bounding boxes.
\end{itemize}
Daarnaast wordt het model getest op real-world data om de prestaties in praktijksituaties te valideren.

\subsection{Vergelijking met Alternatieve Methodes}
Een vergelijking wordt uitgevoerd tussen het YOLO-model en alternatieve technieken zoals OCR-gebaseerde detectie (bijvoorbeeld Tesseract). Hierbij wordt gekeken naar:
\begin{itemize}
    \item Snelheid van detectie;
    \item Nauwkeurigheid in verschillende lichtomstandigheden en hoeken;
    \item Robuustheid tegen variaties in verpakkingsontwerpen.
\end{itemize}
%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

Op basis van eerdere studies en verwachte modelprestaties worden de volgende resultaten verwacht:
\begin{itemize}
    \item Het YOLO-model zal in staat zijn om producttitels op verpakkingen nauwkeurig te detecteren en te onderscheiden van andere elementen op de verpakking.
    \item De implementatie van het model binnen het Self Check-out systeem zal leiden tot een verbeterde productherkenning, vooral bij sterk gelijkende producten.
    \item De combinatie van objectdetectie en tekstdetectie zal zorgen voor een robuuster systeem dat beter bestand is tegen uitdagende winkelomstandigheden, zoals overlappende objecten en slechte belichting.
    \item Vergelijking met OCR-gebaseerde methodes zal aantonen dat YOLO een snellere en mogelijk nauwkeurigere methode is voor real-time producttitelherkenning.
\end{itemize}

\subsection{Conclusie}
Dit onderzoek richt zich op het verbeteren van productdetectie binnen het Self Check-out systeem van Colruyt door een YOLO-model te trainen voor producttitelherkenning. Door het gebruik van deep learning en een hoogwaardige dataset verzameld via de fotobooth, wordt verwacht dat het model een significante bijdrage levert aan de nauwkeurigheid van het systeem. Dit kan resulteren in een snellere en efficiëntere check-out ervaring voor klanten en medewerkers. Verdere optimalisatie en validatie met real-world tests zullen uitwijzen hoe goed het model presteert in praktijksituaties.