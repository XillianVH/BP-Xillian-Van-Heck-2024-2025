%---------- Inleiding ---------------------------------------------------------
\section{Inleiding}%
\label{sec:inleiding}

Binnen de Colruyt Group wordt er binnen de afdeling Smart Innovations gewerkt aan technologieën om het winkelproces efficiënter en klantvriendelijker te maken. Een van deze innovaties is het \textit{easy Self Check-out systeem}, dat gebruik maakt van camera’s aan de kassa om automatisch te detecteren welke producten er in de winkelkar liggen. Dit systeem maakt gebruik van een YOLO-gebaseerd objectdetectiemodel om producten te herkennen, maar ondervindt momenteel moeilijkheden bij het onderscheiden van sterk gerelateerde producten, vooral producten met gelijkaardige verpakkingen.

Om dit probleem aan te pakken, richt dit onderzoek zich op het trainen van een aanvullend YOLO-model dat producttitels op verpakkingen kan herkennen, op basis van afbeeldingen van de producten. Door de titels op de verpakking van producten te herkennen, kan het model producten beter onderscheiden en de nauwkeurigheid van het Check-out systeem verbeteren. Binnen de afdeling Smart Innovations van Colruyt is een fotobooth gebouwd met meerdere camera’s en een draaitafel om afbeeldingen van producten uit verschillende hoeken vast te leggen. Deze beelden worden vervolgens gelabeld met de locaties van titels op de verpakkingen.

\subsection*{Onderzoeksvraag}
De centrale onderzoeksvraag luidt:

\begin{center}
    \textit{Hoe kan een YOLO-model voor producttitelherkenning de nauwkeurigheid van productdetectie binnen het Self Check-out systeem van Colruyt verbeteren?}
\end{center}

\subsection*{Onderzoeksdoelstelling}
De onderzoeksdoelstelling is het creëren van een model dat producttitels accuraat kan detecteren en dat getest wordt op verschillende producten. Het eindresultaat omvat niet alleen een getraind model, maar ook een analyse van de prestaties, inclusief validatietesten. Dit onderzoek biedt een meerwaarde voor Colruyt, omdat het de efficiëntie en betrouwbaarheid van het Self Check-out systeem verhoogt. Hierdoor kunnen zowel klanten als medewerkers van de winkels profiteren van een snellere en betere werking van het Check-out systeem.

%---------- Stand van zaken ---------------------------------------------------

\section{Literatuurstudie}%
\label{sec:literatuurstudie}

\subsection{Objectdetectie en Neurale Netwerken}

\subsubsection{Wat is objectdetectie en hoe werkt het?}
Objectdetectie is een combinatie van objectclassificatie en lokalisatie. Deze techniek lokaliseert objecten binnen een afbeelding en voert per bounding box een classificatie uit. Bij het lokaliseren van de objecten wordt er binnen de afbeelding een rechthoek of bounding box rond een object getekend. Deze bounding boxen worden vervolgens geclassificeerd.

In de context van dit onderzoek betekent dit dat de titels die op de afbeelding te zien zijn, moeten worden gelokaliseerd en vervolgens moeten worden geclassificeerd als een product \autocite{wulteputteefficient}.

\subsubsection{Uitleg over Convolutional Neural Networks (CNNs) en hun rol in objectdetectie}
Convolutional Neural Networks (CNNs) zijn speciaal ontworpen om efficiënt om te gaan met meerdimensionale invoer, zoals afbeeldingen, door gebruik te maken van een techniek die convolutie wordt genoemd. In tegenstelling tot klassieke neurale netwerken, die werken met eendimensionale vectoren, zijn CNN's in staat om belangrijke informatie uit aanliggende pixels te halen, waardoor ze veel effectiever zijn voor taken zoals objectdetectie.

Een CNN bestaat uit verschillende lagen, waarvan de belangrijkste de convolutionele lagen zijn. In deze lagen wordt een set filters (of kernels) over de afbeelding geschoven. Elke filter leert specifieke kenmerken van de afbeelding, zoals randen of kleurovergangen. Door deze filters toe te passen op verschillende delen van de afbeelding ontstaat er een feature map \autocite{wulteputteefficient}. 

Als je bijvoorbeeld een foto van een hond hebt, zal het CNN eerst kleine basiselementen leren, zoals randen en hoeken. Later in het netwerk worden die basiskenmerken samengevoegd tot grotere objectkenmerken, zoals de oren, ogen en poten van de hond. Dit maakt de CNN krachtig voor beeldherkenning.

\subsubsection{Verschillende objectdetectiemethoden}
\begin{itemize}
    \item \textbf{RCNN (Region-based Convolutional Neural Networks)}: Verdeelt een afbeelding in meerdere regio’s en gebruikt een CNN om elk van deze regio’s te classificeren.
    \item \textbf{Fast RCNN}: Een verbeterde versie van RCNN waarbij de afbeelding eerst door een CNN wordt gehaald om feature maps te verkrijgen, waaruit regio’s worden gehaald en geclassificeerd.
    \item \textbf{Faster RCNN}: Maakt gebruik van een Region Proposal Network (RPN) om regio’s automatisch voor te stellen.
    \item \textbf{SSD (Single Shot Multibox Detector)}: Verdeelt de afbeeldingen in meerdere cellen en voorspelt gelijktijdig objecten en hun locaties in één enkele stap.
    \item \textbf{YOLO (You Only Look Once)}: Verdeelt de afbeeldingen in een raster en voorspelt objecten en hun locaties in dezelfde stap.
\end{itemize}

\subsubsection{Waarom is YOLO geschikt voor real-time productdetectie?}
YOLO is geschikt voor real-time productdetectie omdat het alles in één keer doet. Het verdeelt de afbeelding in een raster en voorspelt gelijktijdig alle objecten en hun locaties in één doorlopende stap, zonder dat het meerdere keren door de afbeelding hoeft te bewegen. Dit maakt het zeer snel en in staat om beelden in real-time te verwerken, wat essentieel is voor toepassingen waar snelheid cruciaal is.

\subsection{Productherkenning in Retail}
\begin{itemize}
    \item Hoe wordt objectdetectie in de retailsector toegepast?
    \item Uitdagingen bij productherkenning in supermarkten (bv. overlappende objecten, gelijkaardige verpakkingen).
    \item Vergelijking met andere technieken zoals RFID, barcode-scanning en OCR (Optical Character Recognition).
\end{itemize}

\subsection{Producttitelherkenning met AI}
\begin{itemize}
    \item Wat is tekstdetectie en -herkenning (OCR) en hoe verschilt het van objectdetectie?
    \item Verschil tussen OCR-gebaseerde technieken (zoals Tesseract) en AI-modellen zoals YOLO voor tekstherkenning.
    \item Uitdagingen bij tekstherkenning op verpakkingen (bijv. schuine hoeken, slechte belichting, reflectie).
\end{itemize}

\subsection{Dataverzameling en Annotatie voor AI-Modellen}
\begin{itemize}
    \item Het belang van een kwalitatieve dataset voor YOLO-training.
    \item Hoe werkt data-annotatie (bounding boxes, labels, tools zoals LabelImg of Roboflow)?
    \item Hoe de fotobooth en draaitafel helpen bij het verzamelen van consistente data.
\end{itemize}

\subsection{Evaluatie en Validatie van Objectdetectiemodellen}
\begin{itemize}
    \item Welke metriek(en) gebruik je om je YOLO-model te evalueren? (bv. mAP (mean Average Precision), recall, precision, IoU (Intersection over Union)).
    \item Hoe test je je model op real-world data en zorg je voor een betrouwbare validatie?
\end{itemize}

\subsection{Vergelijking met Alternatieve Oplossingen}
\begin{itemize}
    \item Zijn er andere deep learning-modellen die beter geschikt zouden kunnen zijn?
    \item Kunnen hybride technieken (bv. combinatie van OCR en YOLO) de nauwkeurigheid verbeteren?
    \item Hoe verhoudt jouw aanpak zich tot bestaande state-of-the-art oplossingen in de industrie?
\end{itemize}


% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

Je mag deze sectie nog verder onderverdelen in subsecties als dit de structuur van de tekst kan verduidelijken.

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

Dit onderzoek volgt een experimentele aanpak waarbij een YOLO-model wordt getraind en geëvalueerd voor producttitelherkenning. De methodologie bestaat uit de volgende fasen:

\subsection{Dataverzameling}
Voor de training van het model wordt een dataset samengesteld met behulp van de fotobooth van Colruyt. De fotobooth maakt het mogelijk om producten vanuit verschillende hoeken vast te leggen, wat zorgt voor een diverse dataset. De verzamelde afbeeldingen worden gelabeld met bounding boxes rond de producttitels.

\subsection{Modeltraining}
Het YOLO-model wordt getraind met de geannoteerde dataset. Hiervoor wordt gebruik gemaakt van de volgende aanpak:
\begin{itemize}
    \item Pre-processing van afbeeldingen (resolutie-aanpassing, normalisatie);
    \item Data augmentatie om de robuustheid van het model te verhogen;
    \item Training van het YOLO-model met behulp van deep learning frameworks zoals TensorFlow of PyTorch;
    \item Hyperparameter-tuning voor optimale prestaties.
\end{itemize}

\subsection{Evaluatie en Validatie}
Het model wordt geëvalueerd met behulp van verschillende prestatie-indicatoren:
\begin{itemize}
    \item \textbf{mAP (mean Average Precision)}: meet de gemiddelde precisie van het model over verschillende objectcategorieën.
    \item \textbf{Recall en Precision}: bepalen hoe goed het model relevante objecten detecteert en incorrecte detecties minimaliseert.
    \item \textbf{IoU (Intersection over Union)}: meet de overlap tussen de voorspelde en werkelijke bounding boxes.
\end{itemize}
Daarnaast wordt het model getest op real-world data om de prestaties in praktijksituaties te valideren.

\subsection{Vergelijking met Alternatieve Methodes}
Een vergelijking wordt uitgevoerd tussen het YOLO-model en alternatieve technieken zoals OCR-gebaseerde detectie (bijvoorbeeld Tesseract). Hierbij wordt gekeken naar:
\begin{itemize}
    \item Snelheid van detectie;
    \item Nauwkeurigheid in verschillende lichtomstandigheden en hoeken;
    \item Robuustheid tegen variaties in verpakkingsontwerpen.
\end{itemize}
%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

Op basis van eerdere studies en verwachte modelprestaties worden de volgende resultaten verwacht:
\begin{itemize}
    \item Het YOLO-model zal in staat zijn om producttitels op verpakkingen nauwkeurig te detecteren en te onderscheiden van andere elementen op de verpakking.
    \item De implementatie van het model binnen het Self Check-out systeem zal leiden tot een verbeterde productherkenning, vooral bij sterk gelijkende producten.
    \item De combinatie van objectdetectie en tekstdetectie zal zorgen voor een robuuster systeem dat beter bestand is tegen uitdagende winkelomstandigheden, zoals overlappende objecten en slechte belichting.
    \item Vergelijking met OCR-gebaseerde methodes zal aantonen dat YOLO een snellere en mogelijk nauwkeurigere methode is voor real-time producttitelherkenning.
\end{itemize}

\subsection{Conclusie}
Dit onderzoek richt zich op het verbeteren van productdetectie binnen het Self Check-out systeem van Colruyt door een YOLO-model te trainen voor producttitelherkenning. Door het gebruik van deep learning en een hoogwaardige dataset verzameld via de fotobooth, wordt verwacht dat het model een significante bijdrage levert aan de nauwkeurigheid van het systeem. Dit kan resulteren in een snellere en efficiëntere check-out ervaring voor klanten en medewerkers. Verdere optimalisatie en validatie met real-world tests zullen uitwijzen hoe goed het model presteert in praktijksituaties.